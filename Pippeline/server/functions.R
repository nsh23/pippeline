# helper functions

# Determine the filenames of the data sources.
# @return A character vector with filenames
getDataFiles <- function() {
  row <- which( ( options[ , 'Design'] == input$dsg &
                    options[ , 'Location'] == input$loc &
                    options[ , 'Material'] == input$mat &
                    options[ , 'Analysis'] == input$ana ) )
  if( row < 1) {
    showNotification( 'No data found. (Check file with available options?) Error code #1.', type = 'error')
    return( NULL)
  }
  ## fixme: trengs Subfile?
  files <- as.vector( unname( unlist( options[ row, c( 'File1', 'File2', 'File3') ] ) ) )
  files <- files[ files != '']
  return( files) # fixme
  areReadable = ( file.access( files, 4) > -1)
  if( sum( areReadable) != length( areReadable) ) {
    showNotification( 'Data source not readable. (Check file with available options?) Error code #2.', type = 'error')
    return( NULL)
  }
} # function getDataFiles

# Format a code line as a comment.
# @param string: Code line
# @return string
cmt <- function( line) {
  paste( "#'", line)
}

# Wrap a string in quotes.
# @param string
# @return string
wrapInQuotes <- function( string) {
  paste0( '"', string, '"')
}

# Create a list object to store the attributes of a processing step.
# @param string: step label
# @param character vector: step explanation
# @param boolean: true if step is enabled, false otherwise
# @param character vector: code line strings
# @return list
createStep <- function( label, explanation = c(), enabled = FALSE, code = c() ) {
  list( label = label, expl = explanation, enabled = enabled, code = code)
}

# Generate the documentation for all processing steps.
# @param list object with processing pipeline attributes
# @return character vector: code lines
documentSteps <- function( pipeline) {
  doc <- c()
  for( step in pipeline) {
    if( step$enabled) {
      doc <- c(
        doc,
        '',
        cmt( step$label),
        cmt( step$expl),
        step$code
      )
    }
  }
  return( doc)
} # function documentSteps

# Write the code that instantiates both the processing and documentation of a processing pipeline.
# @param list object with pipeline attributes
# @param string: filename to write the code to
writeScript <- function( pipeline, scriptFile) {
  doc <- c(
    ## YAML
    cmt( '---'),
    cmt( paste( 'title:', wrapInQuotes( basics$title) ) ),
    cmt( paste( 'author:', wrapInQuotes( input$author) ) ),
    cmt( paste( 'date:', wrapInQuotes( ts) ) ),
    cmt( '---'),
    ## header
    cmt( ''),
    cmt( 'This document describes how the associated biobank dataset was prepared.'),
    cmt( paste0( 'It was generated by ', basics$appName, ', version ', basics$appVersion, '.') ),
    cmt( ''),
    cmt( 'Start of pipeline'),
    # fixme: include packageVersion of all statistical scripts
    cmt( paste( 'Pipeline name:', input$name) ),
    cmt( paste( 'Description:', input$descr) ),
    cmt( paste( 'Design:', input$dsg) ),
    cmt( paste( 'Probe location:', input$loc) ),
    cmt( paste( 'Biological material:', input$mat) ),
    cmt( paste( 'Genomic analysis:', input$ana) ),
    ## steps, incl. read and write
    documentSteps( pipeline),
    ## footer
    '',
    cmt( 'End of pipeline')
  )
  writeLines( doc, scriptFile)
} # function writeScript

# Run a script (file) to compute all resulting data and produce its documentation.
# @param string: filename of script
# @param string: filename for documentation
produceDocumenationAndData <- function( scriptFile, docFile) {
  # note: pandoc'ing with target PDF is buggy in R 3.2.3, rmarkdown 1.4, pandoc 1.16.0.2
  render( scriptFile, paste0( basics$docFormat, '_document'), docFile)
} # function produceDocumenationAndData

# Build a list object which keeps all pipeline details stored. fixme
# @param list: parameters
# @return list: pipeline attributes
generatePipeline <- function( params) {
  # details for mandatory processing steps
  readStep <- createStep( 'Datasets', 'Reading in datasets', TRUE, c(
    paste0( 'data = read( ', wrapInQuotes( 'fixme'), ')')
  ) )
  anoStep <- createStep( 'Anonymization', 'Removal of all IDs and running numbers', TRUE, c(
    paste0( 'fixme')
  ) )
  writeStep <- createStep( 'Storage', 'Writing processed datasets', TRUE, c(
    paste0( 'write.csv( data, ', wrapInQuotes( params$targetFile), ')')
  ) )
  # details for non-mandatory processing steps
  exclStep <- createStep( 'Transitions', 'Exclusion of control-case transitions', input$trans, c(
  ) )
  outlStep <- createStep( 'Outliers', 'Removal of outliers', input$outlierEnabled, c(
  ) )
  bcorrStep <- createStep( 'Background correction', '', input$corrEnabled, c(
  ) )
  filtStep <- createStep( 'Probe filtering', '', input$filtEnabled, c(
  ) )
  normStep <- createStep( 'Normalization', '', input$normEnabled, c(
  ) )
  questStep <- createStep( 'Questionnaires', '', input$questEnabled, c(
  ) )
  # now concatenate all steps
  list(
    readStep, # mandatory
    exclStep,
    outlStep,
    bcorrStep,
    filtStep,
    normStep,
    questStep,
    anoStep, # mandatory
    writeStep # mandatory
  )
} # function generatePipeline

