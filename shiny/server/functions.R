# helper functions

# Determine the filenames of the data sources.
# @return A character vector with filenames
getDataFiles <- function() {
  row <- which( ( options[ , 'Design'] == input$dsg &
                    options[ , 'Location'] == input$loc &
                    options[ , 'Material'] == input$mat &
                    options[ , 'Analysis'] == input$ana ) )
  if( row < 1) {
    showNotification( 'No data found. (Check file with available options?) Error code #1.', type = 'error')
    return( NULL)
  }
  ## fixme: trengs Subfile?
  files <- as.vector( unname( unlist( options[ row, c( 'File1', 'File2', 'File3') ] ) ) )
  files <- files[ files != '']
  return( files) # fixme
  areReadable = ( file.access( files, 4) > -1)
  if( sum( areReadable) != length( areReadable) ) {
    showNotification( 'Data source not readable. (Check file with available options?) Error code #2.', type = 'error')
    return( NULL)
  }
} # function getDataFiles

# Format a code line as a comment.
# @param string: Code line
# @return string
cmt <- function( line) {
  paste( "#'", line)
}

# Create a list object to store the attributes of a processing step.
# @param string: step label
# @param character vector: step explanation
# @param boolean: true if step is enabled, false otherwise
# @param character vector: code line strings
# @return list
createStep <- function( label, explanation = c(), enabled = FALSE, code = c() ) {
  list( label = label, expl = explanation, enabled = enabled, code = code)
}

# Generate the documentation for all processing steps.
# @param list object with processing pipeline attributes
# @return character vector: code lines
documentSteps <- function( pipeline) {
  doc <- c()
  for( step in pipeline) {
    if( step$enabled) {
      doc <- c(
        doc,
        '',
        cmt( step$label),
        cmt( step$expl),
        step$code
      )
    }
  }
  return( doc)
} # function documentSteps

# Write the code that instantiates both the processing and documentation of a processing pipeline.
# @param list object with pipeline attributes
# @param string: filename to write the code to
writeScript <- function( pipeline, scriptFile) {
  pkgInfo = read.dcf( file.path( '..', 'DESCRIPTION'), fields = c( 'Package', 'Version') )
  doc <- c(
    ## YAML
    cmt( '---'),
    cmt( paste0( 'title: "', basics$title, '"') ),
    cmt( paste0( 'author: "', input$author, '"') ),
    cmt( paste0( 'date: "', ts, '"') ),
    cmt( '---'),
    ## header
    cmt( ''),
    cmt( 'This document describes how the associated biobank dataset was prepared.'),
    cmt( paste0( 'It was generated by ', basics$appName, ', an app included in package ', pkgInfo[ 1], ', version ', pkgInfo[ 2], '.') ),
    cmt( 'See the R directory for documentation and implementation of statistical functions.'),
    cmt( ''),
    cmt( 'Start of pipeline'),
    cmt( ''),
    cmt( paste( 'Processing description:', input$descr) ),
    cmt( paste( 'Design:', input$dsg) ),
    cmt( paste( 'Probe location:', input$loc) ),
    cmt( paste( 'Biological material:', input$mat) ),
    cmt( paste( 'Genomic analysis:', input$ana) ),
    cmt( paste( 'File name(s) of data source taken from file:', basics$optionsFile) ),
    ## steps, incl. read and write
    documentSteps( pipeline),
    ## footer
    '',
    cmt( 'End of pipeline')
  )
  writeLines( doc, scriptFile)
} # function writeScript

# Build a list object which keeps all pipeline details stored.
# @param list: parameters
# @return list: pipeline attributes
generatePipeline <- function( params) {
  numberOfRuns <- length( params$sourceFiles)
  idxSeq <- 1 : numberOfRuns
  # details for mandatory processing steps
  # reading
  instrs <- c(   # instructions
    sprintf( 'data <- vector(length=%d)', numberOfRuns),
    sprintf( 'data[%d] <- read.csv("%s")', idxSeq, params$sourceFiles[ idxSeq] )
  )
  readStep <- createStep( 'Datasets', 'Reading in datasets', TRUE, instrs)

  # combination
  args <- paste( sprintf( 'data[%d]', idxSeq), collapse = ',')
  instrs <- c(
    sprintf( 'data <- combine(%s)', args) # fixme: Marit: må kunne håndtere kun 1 argument
  )
  combStep <- createStep( 'Combination', 'Combine all runs', TRUE, instrs)
  
  # anonymization
  instrs <- c(
    cmt( 'fixme: NR')
  )
  anoStep <- createStep( 'Anonymization', 'Removal of all IDs and running numbers', TRUE, instrs)

  # storage
  if( input$wantProbes)
    instrs <- c(
      cmt( 'The target data file contains probes.')
    )
  else
    instrs <- c(
      cmt( 'The target data file contains genes.'),
      cmt( 'fixme: NR'),
      'data <- mapToGenes( data)'
    )
  instrs <- c(
    instrs,
    sprintf( 'write.csv( data, "%s")', params$targetFile)
  )
  writeStep <- createStep( 'Storage', 'Writing processed datasets', TRUE, instrs)
  
  # details for non-mandatory processing steps
  # control transitions
  instrs <- c(
    cmt( 'fixme: UiT')
  )
  exclStep <- createStep( 'Transitions', 'Exclusion of control-case transitions', input$trans, instrs)

  # outliers
  instrs <- c(
    cmt( 'fixme: UiT')
  )
  outlStep <- createStep( 'Outliers', 'Removal of outliers', input$outlierEnabled, instrs)

  # background correction
  instrs <- c(
    cmt( 'fixme: NR'),
    sprintf( 'data[%d] <- performBackgroundCorrection( data[%1$d]$lumi, data[%1$d]$expr, data[%1$d]$negCtrl)', idxSeq)
  )
  bcorrStep <- createStep( 'Background correction', '', input$corrEnabled, instrs)
  
  # probe filtering
  instrs <- c(
    cmt( 'fixme: NR'),
    sprintf( 'pValue <- %1.2f', input$pval),
    sprintf( 'pLimit <- %1.2f', input$plimit),
    'data <- filterData(data,pValue,pLimit)'
  ) 
  filtStep <- createStep( 'Probe filtering', '', input$filtEnabled, instrs)
  
  # normalization
  instrs <- c(
    cmt( 'fixme: NR'),
    sprintf( 'data <- normalizeData(data,"%s")', input$nmeth)
  )
  normStep <- createStep( 'Normalization', '', input$normEnabled, instrs)
  
  # questionnaires 
  questStep <- createStep( 'Questionnaires', '', input$questEnabled, c(
    cmt( 'fixme: UiT/NR')
  ) )
  
  # now concatenate all steps
  list(
    readStep, # mandatory
    exclStep,
    outlStep,
    bcorrStep,
    combStep, # mandatory
    filtStep,
    normStep,
    questStep,
    anoStep, # mandatory
    writeStep # mandatory
  )
} # function generatePipeline

