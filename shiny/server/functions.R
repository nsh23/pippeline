# helper functions

# Determine the filenames of the data sources.
# @return A character vector with filenames
getDataFiles <- function() {
  row <- which( ( options[ , 'Design'] == input$dsg &
                    options[ , 'Location'] == input$loc &
                    options[ , 'Material'] == input$mat &
                    options[ , 'Analysis'] == input$ana ) )
  if( row < 1) {
    showNotification( 'No data found. (Check file with available options?) Error code #1.', type = 'error')
    return( NULL)
  }
  files <- as.vector( unname( unlist( options[ row, c( 'File1', 'File2', 'File3') ] ) ) )
  files <- files[ files != '']
  return( files) # fixme
  areReadable = ( file.access( files, 4) > -1)
  if( sum( areReadable) != length( areReadable) ) {
    showNotification( 'Data source not readable. (Check file with available options?) Error code #2.', type = 'error')
    return( NULL)
  }
} # function getDataFiles

# Format a code line as a comment.
# @param string: Code line
# @return string
cmt <- function( line = '') {
  paste( "#'", line)
}

# Create a list object to store the attributes of a processing step.
# @param string: step label
# @param character vector: step explanation
# @param boolean: true if step is enabled, false otherwise
# @param function which generates a vector with code line strings
# @param arguments to the function call
# @return mixed: list if enabled, NULL otherwise
createStep <- function( label, 
                        explanation = c(), 
                        enabled = FALSE, 
                        generateCode = function(){c()}, 
                        args = list() ) {
  if( enabled)
    list( 
      label = label, 
      expl = explanation, 
      enabled = enabled, 
      code = do.call( generateCode, args)
    )
  else
    NULL
}

# Generate the documentation for all processing steps.
# @param list object with processing pipeline attributes
# @return character vector: code lines
documentSteps <- function( pipeline) {
  doc <- c()
  for( step in pipeline) {
    if( !is.null( step) &&
        step$enabled) {
      doc <- c(
        doc,
        '',
        cmt( paste( '#', step$label) ),
        cmt( step$expl),
        step$code
      )
    }
  }
  return( doc)
} # function documentSteps

# Write the code that instantiates both the processing and documentation of a processing pipeline.
# @param list object with pipeline attributes
# @param string: filename to write the code to
writeScript <- function( pipeline, 
                         scriptFile) {
  pkgInfo = read.dcf( file.path( '..', 'DESCRIPTION'), fields = c( 'Package', 'Version') )
  doc <- c(
    # YAML
    cmt( '---'),
    cmt( paste0( 'title: "', basics$title, '"') ),
    cmt( paste0( 'author: "', input$author, '"') ),
    cmt( paste0( 'date: "', ts, '"') ),
    cmt( '---'),
    # header
    cmt(),
    cmt( 'This document describes how the associated biobank dataset was prepared.'),
    cmt( paste0( 'It was generated by ', basics$appName, ', an application included in the R package ', pkgInfo[ 1], ', version ', pkgInfo[ 2], '.') ),
    cmt( 'See the R directory for documentation and implementation of statistical functions.'),
    cmt(),
    cmt( '***'),
    cmt(),
    cmt( '# Basic choices'),
    cmt( paste( '* Processing description:', input$descr) ),
    cmt( paste( '* Design:', input$dsg) ),
    cmt( paste( '* Probe location:', input$loc) ),
    cmt( paste( '* Biological material:', input$mat) ),
    cmt( paste( '* Genomic analysis:', input$ana) ),
    cmt(),
    cmt( paste( 'File name(s) of data source taken from file:', basics$optionsFile) ),
    '',
    sprintf( 'source("%s")', file.path( system.file( package = pkgInfo[ 1], mustWork=TRUE), 'R', 'NR_functions.R') ),
    # steps, incl. read and write
    documentSteps( pipeline),
    # footer
    '',
    cmt( '***')
  )
  writeLines( doc, scriptFile)
} # function writeScript

# Build a list object which keeps all pipeline details stored.
# @param list: parameters
# @return list: pipeline attributes
generatePipeline <- function( params) {
  numberOfRuns <- length( params$sourceFiles)
  idxSeq <- 1 : numberOfRuns
  # details for mandatory processing steps
  # step: reading
  generateCode <- function( vecLength, idxSeq, file) {
    c(   # instructions
      sprintf( '##data <- vector(length=%d)', vecLength),
      sprintf( '##data[%d] <- read.csv("%s")', idxSeq, file)
    )
  }
  readStep <- createStep( 'Datasets', 'Reading in datasets', TRUE, generateCode, list( numberOfRuns, idxSeq, params$sourceFiles[ idxSeq] ) )
  
  # step: combination
  generateCode <- function( idxSeq) {
    if( numberOfRuns > 1) {
      args <- paste( sprintf( 'data[%d]', idxSeq), collapse = ',')
      c( sprintf( '##data <- combine(%s)', args) )
    } else {
      c( sprintf( '##data <- data[1]') )
    }
  }
  combStep <- createStep( 'Combination', 'Combining all runs.', TRUE, generateCode, list( idxSeq) )
  
  # step: anonymization
  generateCode <- function() {
    c(
      '## fixme: NR'
    )
  }
  anoStep <- createStep( 'Anonymization', 'Removal of all IDs and running numbers.', TRUE, generateCode)

  # step: storage
  generateCode <- function( file) {
    if( input$wantProbes)
      ins <- c(
        cmt( 'The target data file contains probes.')
      )
    else
      ins <- c(
        cmt( 'The target data file contains genes.'),
        '## fixme: NR',
        '##data <- mapToGenes(data)'
      )
    c(
      ins,
      sprintf( 'save(pValue, file="%s")', file) # fixme: data
    )
  }
  writeStep <- createStep( 'Storage', 'Writing processed datasets.', TRUE, generateCode, list( params$targetFile) )
  
  # details for non-mandatory processing steps
  # step: control transitions
  generateCode <- function() {
    c(
      '## fixme: UiT'
    )
  }
  exclStep <- createStep( 'Transitions', 'Exclusion of control-case transitions.', input$trans, generateCode)

  # step: outliers
  generateCode <- function() {
    outlierFile <- input$outlierFile$datapath
    if( length( outlierFile) == 0 ||
        as.integer( file.access( outlierFile, mode = 4) ) < 0)
      showNotification( 'Could not read outlier file. Error code #4.', type = 'error')  
    c(
      cmt(),
      cmt( paste( 'Identification of outliers:', ifelse( input$outlierDescr != '', input$outlierDescr, 'Not described') ) ),
      sprintf( 'load("%s")', outlierFile),
      'for_removal',
      '## fixme: remove outliers'
    )
  }
  outlStep <- createStep( 'Outliers', 'Removal of outliers.', input$outlierEnabled, generateCode)

  # step: background correction
  generateCode <- function( idxSeq) {
    c(
      '## fixme: NR',
      sprintf( '##data[%d] <- performBackgroundCorrection(data[%1$d]$lumi, data[%1$d]$expr, data[%1$d]$negCtrl)', idxSeq)
    )
  }
  bcorrStep <- createStep( 'Background correction', '', input$corrEnabled, generateCode, list( idxSeq) )
  
  # step: probe filtering
  generateCode <- function() {
    c(
      '## fixme: NR',
      sprintf( 'pValue <- %1.2f', input$pval),
      sprintf( 'pLimit <- %1.2f', input$plimit),
      '##data <- filterData(data,pValue,pLimit)'
    ) 
  }
  filtStep <- createStep( 'Probe filtering', '', input$filtEnabled, generateCode)
  
  # step: normalization
  generateCode <- function() {
    c(
      '## fixme: NR',
      sprintf( '##data <- normalizeData(data,"%s")', input$nmeth)
    )
  }
  normStep <- createStep( 'Normalization', '', input$normEnabled, generateCode)
  
  # step: questionnaires 
  generateCode <- function() {
    c(
      '## fixme: UiT/NR'
    )
  }
  questStep <- createStep( 'Questionnaires', '', input$questEnabled, generateCode)
  
  # now concatenate all steps
  list(
    readStep, # mandatory
    exclStep,
    outlStep,
    bcorrStep,
    combStep, # mandatory
    filtStep,
    normStep,
    questStep,
    anoStep, # mandatory
    writeStep # mandatory
  )
} # function generatePipeline

